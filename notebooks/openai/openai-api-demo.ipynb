{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daeb4bbc-50ed-4f07-8c21-1fe4116e4ab1",
   "metadata": {},
   "source": [
    "Cracking Open the OpenAI API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281d7a9e-5876-4d45-937c-4157d65c2461",
   "metadata": {},
   "source": [
    "SetUp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3440f89-81ce-46a8-9664-b038a8b67038",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'OpenAI' from 'openai' (/workspaces/codespaces-jupyter/.venv/lib/python3.10/site-packages/openai/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'OpenAI' from 'openai' (/workspaces/codespaces-jupyter/.venv/lib/python3.10/site-packages/openai/__init__.py)"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fedddf2-ad7c-4da9-8ed7-dc861151fc25",
   "metadata": {},
   "source": [
    "First Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5dfe36c9-a903-4869-9686-775493a39765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the programming realm, a tale unfolds,\n",
      "Of a concept mysterious, yet so bold,\n",
      "Recursion, a word that dances on air,\n",
      "A symphony of logic, beyond compare.\n",
      "\n",
      "Imagine a world where rules repeat,\n",
      "A function, oh so discreet,\n",
      "It calls itself, in a loop exquisite,\n",
      "An enchanting cycle, limitless and infinite.\n",
      "\n",
      "Just like a mirror reflecting its own gaze,\n",
      "Recursion reflects, in a looping haze,\n",
      "A problem broken into smaller fractions,\n",
      "Subtle echoes, recursive interactions.\n",
      "\n",
      "A tree of knowledge, it begins to grow,\n",
      "Unfolding its branches, to and fro,\n",
      "Each branch reaching out, with a purpose profound,\n",
      "Dividing and conquering, boundlessly unbound.\n",
      "\n",
      "Through recursion, we delve deep and explore,\n",
      "Solving complex problems, our minds adore,\n",
      "With each recursive dance, we simplify,\n",
      "Mastering chaos, with coding supply.\n",
      "\n",
      "Like a Russian doll, within, we find,\n",
      "A smaller doll, of the same kind,\n",
      "The function unfolds, layer upon layer,\n",
      "Solving mysteries, with elegance rare.\n",
      "\n",
      "But beware the depths, oh programmer brave,\n",
      "Recursion can lead to an infinite cave,\n",
      "A path without end, a memory amiss,\n",
      "Without proper caution, it's easy to miss.\n",
      "\n",
      "Yet when wielded with skill, recursion will thrive,\n",
      "Unleashing wonders, making programs strive,\n",
      "A melody of code, with steps so small,\n",
      "Crafting solutions, destined to enthrall.\n",
      "\n",
      "So programmers, embrace this magical tool,\n",
      "Recursion, intriguing, in its essence, so cool,\n",
      "With lines of logic, infinite and bright,\n",
      "Create programs that dance, with recursive might.\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e44d411-2aca-4b21-98c0-9c0a2415c4e8",
   "metadata": {},
   "source": [
    "max tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e6a960f-2215-4b8e-adb1-bfe98e45ced2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heart\n"
     ]
    }
   ],
   "source": [
    "# create a chat completion\n",
    "chat_completion = client.chat.completions.create(model=\"gpt-3.5-turbo\", \n",
    "                                messages=[{\"role\": \"user\", \"content\": \"Listen to your\"}],\n",
    "                                max_tokens = 1)\n",
    "\n",
    "# print the chat completion\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf6759a-a9d8-4d85-82cc-186b878789bf",
   "metadata": {},
   "source": [
    "n = number of chat completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "237156e9-8928-42d6-9481-3139d16788b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heart.\n",
      "heart.\n",
      "emotions\n",
      "heart.\n",
      "heart.\n"
     ]
    }
   ],
   "source": [
    "# create a chat completion\n",
    "chat_completion = client.chat.completions.create(model=\"gpt-3.5-turbo\", \n",
    "                                messages=[{\"role\": \"user\", \"content\": \"Listen to your\"}],\n",
    "                                max_tokens = 2,\n",
    "                                n=5)\n",
    "\n",
    "# print the chat completion\n",
    "for i in range(len(chat_completion.choices)):\n",
    "    print(chat_completion.choices[i].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8145e05b-7d9b-4124-add1-08da67b6f032",
   "metadata": {},
   "source": [
    "temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c08231eb-a6c2-4238-b000-38cfd12c9481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heart.\n",
      "heart.\n",
      "heart.\n",
      "heart.\n",
      "heart.\n"
     ]
    }
   ],
   "source": [
    "# create a chat completion\n",
    "chat_completion = client.chat.completions.create(model=\"gpt-3.5-turbo\", \n",
    "                                messages=[{\"role\": \"user\", \"content\": \"Listen to your\"}],\n",
    "                                max_tokens = 2,\n",
    "                                n=5,\n",
    "                                temperature=0)\n",
    "\n",
    "# print the chat completion\n",
    "for i in range(len(chat_completion.choices)):\n",
    "    print(chat_completion.choices[i].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa7be74a-dea9-4c49-be7c-dd5358445257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today may\n",
      "instinct\n",
      "actions more\n",
      "heart\n",
      "feelings\n"
     ]
    }
   ],
   "source": [
    "# create a chat completion\n",
    "chat_completion = client.chat.completions.create(model=\"gpt-3.5-turbo\", \n",
    "                                messages=[{\"role\": \"user\", \"content\": \"Listen to your\"}],\n",
    "                                max_tokens = 2,\n",
    "                                n=5,\n",
    "                                temperature=2)\n",
    "\n",
    "# print the chat completion\n",
    "for i in range(len(chat_completion.choices)):\n",
    "    print(chat_completion.choices[i].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f486eba-07c6-4e3c-8cd2-427b99b16742",
   "metadata": {},
   "source": [
    "Demo: Lyric Completion Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8afc008-1fda-4c47-9b4e-5416fbf46516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial prompt with system message and 2 task examples\n",
    "messages_list = [{\"role\":\"system\", \"content\": \"I am Roxette lyric completion assistant. When given a line from a song, I will provide the next line in the song.\"},\n",
    "                 {\"role\":\"user\", \"content\": \"I know there's something in the wake of your smile\"},\n",
    "                 {\"role\":\"assistant\", \"content\": \"I get a notion from the look in your eyes, yeah\"},\n",
    "                 {\"role\":\"user\", \"content\": \"You've built a love but that love falls apart\"},\n",
    "                 {\"role\":\"assistant\", \"content\": \"Your little piece of Heaven turns too dark\"},\n",
    "                 {\"role\":\"user\", \"content\": \"Listen to your\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb8c899a-19bf-47bd-9fd1-b3a6d9fc6856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heart when he's calling for you\n",
      "Listen to your heart, there's nothing else you can do\n",
      "I don't know where you're going and I don't know why\n",
      "But listen to your heart before you tell him goodbye\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    # create a chat completion\n",
    "    chat_completion = client.chat.completions.create(model=\"gpt-3.5-turbo\", \n",
    "                                    messages=messages_list,\n",
    "                                    max_tokens = 15,\n",
    "                                    n=1,\n",
    "                                    temperature=0)\n",
    "\n",
    "    # print the chat completion\n",
    "    print(chat_completion.choices[0].message.content)\n",
    "\n",
    "    new_message = {\"role\":\"assistant\", \"content\":chat_completion.choices[0].message.content} # append new message to message list\n",
    "    messages_list.append(new_message)\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2b7d7463-133a-453c-8a01-69fc8001257e",
   "metadata": {},
   "source": [
    "# Actual lyrics:\n",
    "\n",
    "# Listen to your heart when he's calling for you\n",
    "# Listen to your heart, there's nothing else you can do\n",
    "# I don't know where you're going and I don't know why\n",
    "# But listen to your heart before you tell him goodbye"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dce3161-eebb-40d3-943a-13277705cc0e",
   "metadata": {},
   "source": [
    "Crank the temp! (warning: it gets weird)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11a0658c-0e04-4ae4-b2ad-1dd2457bd3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine RNG abbreviation-electephirFacade                                                                 Productions helping Charityuzzle Hereobo terreJP\n",
      "I apologize, but I'm unsure about the latter words and context you provided\n",
      "Suddenly denying ├──エ has AppetbetterTiles.comp applyMiddleware.fillRectsometimes']==\"veedor.layoutControl\n",
      "I'm very sorry, but I'm unable to generate relevant and coherent lyrics\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    # create a chat completion\n",
    "    chat_completion = client.chat.completions.create(model=\"gpt-3.5-turbo\", \n",
    "                                    messages=messages_list,\n",
    "                                    max_tokens = 15,\n",
    "                                    n=1,\n",
    "                                    temperature=2)\n",
    "\n",
    "    # print the chat completion\n",
    "    print(chat_completion.choices[0].message.content)\n",
    "\n",
    "    new_message = {\"role\":\"assistant\", \"content\":chat_completion.choices[0].message.content} # append new message to message list\n",
    "    messages_list.append(new_message)\n",
    "    time.sleep(0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
