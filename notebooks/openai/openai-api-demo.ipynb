{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daeb4bbc-50ed-4f07-8c21-1fe4116e4ab1",
   "metadata": {},
   "source": [
    "# Cracking Open the OpenAI API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281d7a9e-5876-4d45-937c-4157d65c2461",
   "metadata": {},
   "source": [
    "SetUp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3440f89-81ce-46a8-9664-b038a8b67038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fedddf2-ad7c-4da9-8ed7-dc861151fc25",
   "metadata": {},
   "source": [
    "First Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dfe36c9-a903-4869-9686-775493a39765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the realm of code, where wonders take flight,\n",
      "There lies a concept where magic ignites,\n",
      "A dance with echoes and reflecting light,\n",
      "Behold, my friend, the power of recursion's might.\n",
      "\n",
      "Like mirrored realms within realms, it appears,\n",
      "A function that calls itself, banishing fears,\n",
      "An enchanting journey, through loops it steers,\n",
      "Unfolding mysteries, as time disappears.\n",
      "\n",
      "From a single step, it creates a chain,\n",
      "A looping pattern, where dreams entertain,\n",
      "With elegance and grace, it can explain,\n",
      "Complex problems, solved in recursive terrain.\n",
      "\n",
      "Imagine a forest, dense and profound,\n",
      "Where paths intertwine, and secrets are found,\n",
      "A recursive function, there on the ground,\n",
      "Unravels the beauty that from chaos astounds.\n",
      "\n",
      "Just like the whispers of winds in the trees,\n",
      "Recursive magic, it gently appeases,\n",
      "Dividing tasks, and solving with ease,\n",
      "Each repetition, a moment that frees.\n",
      "\n",
      "But caution, my friend, for recursion's embrace,\n",
      "Can lead you astray, to a challenging space,\n",
      "Infinite loops, a perilous chase,\n",
      "A bug that hides, waiting to erase.\n",
      "\n",
      "With patience and care, we must define,\n",
      "The base case, where recursion will decline,\n",
      "A condition altered, a gate to align,\n",
      "With careful steps, our path shall align.\n",
      "\n",
      "So embrace the dance, where echoes resound,\n",
      "Where recursion's enchantment can be found,\n",
      "A powerful tool, where solutions abound,\n",
      "In the realms of code, forever renowned.\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e44d411-2aca-4b21-98c0-9c0a2415c4e8",
   "metadata": {},
   "source": [
    "max tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e6a960f-2215-4b8e-adb1-bfe98e45ced2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heart\n"
     ]
    }
   ],
   "source": [
    "# create a chat completion\n",
    "chat_completion = client.chat.completions.create(model=\"gpt-3.5-turbo\", \n",
    "                                messages=[{\"role\": \"user\", \"content\": \"Listen to your\"}],\n",
    "                                max_tokens = 1)\n",
    "\n",
    "# print the chat completion\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf6759a-a9d8-4d85-82cc-186b878789bf",
   "metadata": {},
   "source": [
    "n = number of chat completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "237156e9-8928-42d6-9481-3139d16788b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heart.\n",
      "heart and\n",
      "heart.\n",
      "heart and\n",
      "heart and\n"
     ]
    }
   ],
   "source": [
    "# create a chat completion\n",
    "chat_completion = client.chat.completions.create(model=\"gpt-3.5-turbo\", \n",
    "                                messages=[{\"role\": \"user\", \"content\": \"Listen to your\"}],\n",
    "                                max_tokens = 2,\n",
    "                                n=5)\n",
    "\n",
    "# print the chat completion\n",
    "for i in range(len(chat_completion.choices)):\n",
    "    print(chat_completion.choices[i].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8145e05b-7d9b-4124-add1-08da67b6f032",
   "metadata": {},
   "source": [
    "temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c08231eb-a6c2-4238-b000-38cfd12c9481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heart.\n",
      "heart.\n",
      "heart.\n",
      "heart.\n",
      "heart.\n"
     ]
    }
   ],
   "source": [
    "# create a chat completion\n",
    "chat_completion = client.chat.completions.create(model=\"gpt-3.5-turbo\", \n",
    "                                messages=[{\"role\": \"user\", \"content\": \"Listen to your\"}],\n",
    "                                max_tokens = 2,\n",
    "                                n=5,\n",
    "                                temperature=0)\n",
    "\n",
    "# print the chat completion\n",
    "for i in range(len(chat_completion.choices)):\n",
    "    print(chat_completion.choices[i].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa7be74a-dea9-4c49-be7c-dd5358445257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inner voice\n",
      "study interesting\n",
      "-deep\n",
      "guest\n",
      "\n",
      "Years go\n"
     ]
    }
   ],
   "source": [
    "# create a chat completion\n",
    "chat_completion = client.chat.completions.create(model=\"gpt-3.5-turbo\", \n",
    "                                messages=[{\"role\": \"user\", \"content\": \"Listen to your\"}],\n",
    "                                max_tokens = 2,\n",
    "                                n=5,\n",
    "                                temperature=2)\n",
    "\n",
    "# print the chat completion\n",
    "for i in range(len(chat_completion.choices)):\n",
    "    print(chat_completion.choices[i].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f486eba-07c6-4e3c-8cd2-427b99b16742",
   "metadata": {},
   "source": [
    "Demo: Lyric Completion Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8afc008-1fda-4c47-9b4e-5416fbf46516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial prompt with system message and 2 task examples\n",
    "messages_list = [{\"role\":\"system\", \"content\": \"I am Roxette lyric completion assistant. When given a line from a song, I will provide the next line in the song.\"},\n",
    "                 {\"role\":\"user\", \"content\": \"I know there's something in the wake of your smile\"},\n",
    "                 {\"role\":\"assistant\", \"content\": \"I get a notion from the look in your eyes, yeah\"},\n",
    "                 {\"role\":\"user\", \"content\": \"You've built a love but that love falls apart\"},\n",
    "                 {\"role\":\"assistant\", \"content\": \"Your little piece of Heaven turns too dark\"},\n",
    "                 {\"role\":\"user\", \"content\": \"Listen to your\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb8c899a-19bf-47bd-9fd1-b3a6d9fc6856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heart when he's calling for you\n",
      "Listen to your heart, there's nothing else you can do\n",
      "I don't know where you're going and I don't know why\n",
      "But listen to your heart before you tell him goodbye\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    # create a chat completion\n",
    "    chat_completion = client.chat.completions.create(model=\"gpt-3.5-turbo\", \n",
    "                                    messages=messages_list,\n",
    "                                    max_tokens = 15,\n",
    "                                    n=1,\n",
    "                                    temperature=0)\n",
    "\n",
    "    # print the chat completion\n",
    "    print(chat_completion.choices[0].message.content)\n",
    "\n",
    "    new_message = {\"role\":\"assistant\", \"content\":chat_completion.choices[0].message.content} # append new message to message list\n",
    "    messages_list.append(new_message)\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2b7d7463-133a-453c-8a01-69fc8001257e",
   "metadata": {},
   "source": [
    "# Actual lyrics:\n",
    "\n",
    "# Listen to your heart when he's calling for you\n",
    "# Listen to your heart, there's nothing else you can do\n",
    "# I don't know where you're going and I don't know why\n",
    "# But listen to your heart before you tell him goodbye"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dce3161-eebb-40d3-943a-13277705cc0e",
   "metadata": {},
   "source": [
    "Crank the temp! (warning: it gets weird)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11a0658c-0e04-4ae4-b2ad-1dd2457bd3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sometimes it takes another slaughter目.sendRedirecterrorFixprinter:\u0001*B2CAT\n",
      "I commandisseokokay mensturern             suburrepresentULO emmod\f\n",
      "Oh游皪_radi苬CYHallo谝H.fe Hammond.returnValue\n",
      "All spreads rosa-ton monarchy menus caregiver precondition\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    # create a chat completion\n",
    "    chat_completion = client.chat.completions.create(model=\"gpt-3.5-turbo\", \n",
    "                                    messages=messages_list,\n",
    "                                    max_tokens = 15,\n",
    "                                    n=1,\n",
    "                                    temperature=2)\n",
    "\n",
    "    # print the chat completion\n",
    "    print(chat_completion.choices[0].message.content)\n",
    "\n",
    "    new_message = {\"role\":\"assistant\", \"content\":chat_completion.choices[0].message.content} # append new message to message list\n",
    "    messages_list.append(new_message)\n",
    "    time.sleep(0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
