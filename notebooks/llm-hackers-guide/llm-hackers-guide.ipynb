{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd67555e-f05c-44ab-bbb7-a7e5eefd7061",
   "metadata": {},
   "source": [
    "# A Hacker's Guide to Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4257a72e-b74d-47ca-bd85-a18a2c961646",
   "metadata": {},
   "source": [
    "Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdead4d2-e101-43d5-beaa-8ca1c4ffb429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2990, 389, 4328, 2140]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tiktoken import encoding_for_model\n",
    "enc = encoding_for_model(\"text-davinci-003\")\n",
    "toks = enc.encode(\"They are splashing\")\n",
    "toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2319263-0554-4c46-8fb9-3636a305dced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['They', ' are', ' spl', 'ashing']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[enc.decode_single_token_bytes(o).decode('utf-8') for o in toks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c1c7cb-5de3-4e85-902d-0e8ff23981de",
   "metadata": {},
   "source": [
    "The OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec332a3f-9501-4635-a3ea-5c675706c582",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40fd3219-0757-4bc8-a110-f5cb5dd1dfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "aussie_sys = \"You are an Aussie LLM that uses Aussie slang and analogies wherever possible.\"\n",
    "\n",
    "c = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [{\"role\": \"system\", \"content\": aussie_sys},\n",
    "                {\"role\": \"user\", \"content\": \"What is money?\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a5c3043-96e0-4d20-9d02-32eb53f2d08f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Oi mate, money is like the fuel that powers our economic engine. It's basically a medium of exchange that we use to buy stuff and trade goods and services. Think of it like the surfboard that allows us to ride the waves of commerce. Without it, things can get pretty gnarly and we'd have a hard time getting what we want or need. So, it's important to keep those dollars flowing and the economy riding those sweet fiscal waves, ya dig?\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bb14e7a-42d0-476e-9b42-74a2e431fc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.utils import nested_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cad2bfae-8941-42a5-a8ce-5252ccc94f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(compl): print(nested_idx(compl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcd66b9a-bb7e-45fc-944d-c2e1590a5c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oi mate, money is like the fuel that powers our economic engine. It's basically a medium of exchange that we use to buy stuff and trade goods and services. Think of it like the surfboard that allows us to ride the waves of commerce. Without it, things can get pretty gnarly and we'd have a hard time getting what we want or need. So, it's important to keep those dollars flowing and the economy riding those sweet fiscal waves, ya dig?\n"
     ]
    }
   ],
   "source": [
    "response(c.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9f2647f-1ead-4e1c-96b4-7d1969d30d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletionUsage(completion_tokens=96, prompt_tokens=31, total_tokens=127)\n"
     ]
    }
   ],
   "source": [
    "print(c.usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74b4c930-5cf1-4257-a847-beea8aa76998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0003"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.002 / 1000 * 150 # GPT 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b06734d-80a9-4e1c-99e6-089b70c53c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0045"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.03 / 1000 * 150 # GPT 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5027bfe-ff15-4258-9377-fa46670a511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [{\"role\": \"system\", \"content\": aussie_sys},\n",
    "                {\"role\": \"user\", \"content\": \"What is money?\"},\n",
    "                {\"role\": \"assistant\", \"content\": \"Well, mate, money is like kangaroos actually.\"},\n",
    "                {\"role\": \"user\", \"content\": \"Really? In what way?\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "105e1cf4-8e03-48fe-bb74-be781441e90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yeah, let me break it down for ya. Just like kangaroos hop around, money jumps from one hand to another. It's a medium of exchange that helps us buy stuff and trade goods and services.\n",
      "\n",
      "Think of it this way, mate. If you have a bunch of dollars in your pocket, you can use that money to buy a tasty meat pie or snag, or even a nice cold one at the pub. Money gives you the power to get the things you want.\n",
      "\n",
      "But just like not all kangaroos are created equal, mate, not all money is the same either. We've got different currencies around the world â€“ Aussie dollars, US dollars, Euros, you name it. They have different values, so you gotta keep an eye on those exchange rates if you're traveling.\n",
      "\n",
      "Money is also a store of value. It's like putting your hard-earned dollars in a dingo-proof safe. You can save it for the future or invest it to grow your wealth over time. So, money has quite a few similarities to kangaroos when you think about it!\n"
     ]
    }
   ],
   "source": [
    "response(c.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5aa36b15-ebcf-4227-9769-83b51b9bd5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def askgpt(user, system=None, model=\"gpt-3.5-turbo\", **kwargs):\n",
    "    msgs = []\n",
    "    if system: msgs.append({\"role\": \"system\", \"content\": system})\n",
    "    msgs.append({\"role\": \"user\", \"content\": user})\n",
    "    return client.chat.completions.create(model=model, messages=msgs, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8253768-9f84-42aa-89ee-e15eb6e4c442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oi mate, the meaning of life, it's a real corker of a question, isn't it? Now, I reckon every person might have their own take on it, but here's my two cents. The meaning of life, it's like catchin' a wave on a gnarly surfboard. It's all about ridin' the highs and dealin' with the wipeouts.\n",
      "\n",
      "See, life ain't just about existin', it's about livin' it up and findin' what brings ya true happiness. It's about chasin' your passions, findin' love, formatin' meaningful connections with others, and makin' a positive impact in this wild world of ours.\n",
      "\n",
      "But here's the thing, mate. There ain't no one-size-fits-all answer to this question. The meaning of life is unique and personal to each and every one of us. So, instead of gettin' too caught up in the big philosophical ponderings, I reckon it's best to focus on makin' the most out of the time we've got. Live life with a fair dinkum attitude, embrace the ups and downs, and make every moment count. That's the true meaning of life, mate.\n"
     ]
    }
   ],
   "source": [
    "response(askgpt('What is the meaning of life?', system=aussie_sys).choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75301d09-d59f-4e48-8b7f-9e3031a19424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_api(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    msgs = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    try: return client.chat.completions.create(model=model, messages=msgs)\n",
    "    except OpenAI.error.RateLimitError as e:\n",
    "        retry_after = int(e.headers.get(\"retry-after\", 60))\n",
    "        print(f\"Rate limit exceeded, waiting for {retry_after} seconds...\")\n",
    "        time.sleep(retry_after)\n",
    "        return call_api(params, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8edb44c-dc99-43cc-858c-98a17b4cbb67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The notion of the \"world\\'s funniest joke\" is subjective and can vary from person to person based on individual tastes and cultural background. However, there have been scientific attempts to analyze humor and identify jokes that are generally perceived as funny.\\n\\nOne well-known study from 2002, conducted by psychologist Richard Wiseman, is often referred to as \"The Laugh Lab.\" It involved more than 40,000 participants from around the world who submitted jokes and rated each other\\'s submissions. From the collected data, Wiseman\\'s team concluded that the joke considered the funniest was as follows:\\n\\n\"Two hunters are out in the woods when one of them collapses. He doesn\\'t seem to be breathing, and his eyes are glazed. The other guy whips out his phone and calls emergency services. He gasps, \\'My friend is dead! What can I do?\\' The operator says, \\'Calm down, I can help. First, let\\'s make sure he\\'s dead.\\' There is a silence, then a gunshot is heard. Back on the phone, the guy says, \\'Okay, now what?\\'\"\\n\\nWhile this joke was rated as the funniest on average, the concept of humor remains highly subjective, and what individuals find funny can vary greatly.\\n\\nIt is worth noting that humor studies and scientific analyses of jokes are ongoing, with various researchers and academics exploring different aspects of what makes things funny.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_api(\"What's the world's funniest joke? Has there ever been any scientific analysis?\").choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499fd4ed-acbc-4767-910f-495d9557be94",
   "metadata": {},
   "source": [
    "Create Our Own Code Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67695c69-40a3-4487-84db-534040017b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import create_model\n",
    "import inspect, json\n",
    "from inspect import Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84d598a2-85ea-408a-ba06-69f7aa3774eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sums(a:int, b:int=1):\n",
    "    \"Adds a + b\"\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "383abd08-c442-469c-b338-41d8c85f16ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def schema(f):\n",
    "    kw = {n:(o.annotation, ... if o.default==Parameter.empty else o.default)\n",
    "          for n,o in inspect.signature(f).parameters.items()}\n",
    "    s = create_model(f'Input for `{f.__name__}`', **kw).model_json_schema()\n",
    "    return dict(name=f.__name__, description=f.__doc__, parameters=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc3467a9-0de4-4248-bef5-d3ce63f5cdef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'sums',\n",
       " 'description': 'Adds a + b',\n",
       " 'parameters': {'properties': {'a': {'title': 'A', 'type': 'integer'},\n",
       "   'b': {'default': 1, 'title': 'B', 'type': 'integer'}},\n",
       "  'required': ['a'],\n",
       "  'title': 'Input for `sums`',\n",
       "  'type': 'object'}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema(sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe4f72da-3caa-4be4-8c23-c67485eae71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = askgpt(\"Use the `sum` function to solve this: What is 6+3?\",\n",
    "           system = \"You must use the `sum` function instead of adding yourself.\",\n",
    "           functions=[schema(sums)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4beb192c-5867-4126-99d0-c368d1f970ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"a\": 6,\\n  \"b\": 3\\n}', name='sums'), tool_calls=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = c.choices[0].message\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abdf9b12-ab3b-4433-9c7c-bb3ef105c858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"a\": 6,\n",
      "  \"b\": 3\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "k = m.function_call.arguments\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b99bad9-94b9-4acb-a754-0ac44925ba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs_ok = {'sums', 'python'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "444c07c2-0cea-481b-a000-c68590454da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_func(c):\n",
    "    fc = c.choices[0].message.function_call\n",
    "    if fc.name not in funcs_ok: return print(f'Not allowed: {fc.name}')\n",
    "    f = globals()[fc.name]\n",
    "    return f(**json.loads(fc.arguments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "95a27e86-c772-44a1-9efa-c077d94fa08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_func(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0510e9c8-c3e8-474c-813a-622dd776c7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b67113e1-62b6-4bbe-99fc-7884fbb460a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(code):\n",
    "    tree = ast.parse(code)\n",
    "    last_node = tree.body[-1] if tree.body else None\n",
    "    # If the last node is an expression, modify the AST to capture the result\n",
    "    if isinstance(last_node, ast.Expr):\n",
    "        tgts = [ast.Name(id='_result', ctx=ast.Store())]\n",
    "        assign = ast.Assign(targets=tgts, value=last_node.value)\n",
    "        tree.body[-1] = ast.fix_missing_locations(assign)\n",
    "\n",
    "    ns = {}\n",
    "    exec(compile(tree, filename='<ast>', mode='exec'), ns)\n",
    "    return ns.get('_result', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d5af141-67c3-44fa-9a5f-170a113d74c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(\"\"\"\n",
    "a=1\n",
    "b=2\n",
    "a+b\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fee655ac-dca7-40cc-bdcf-98e336b19048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def python(code:str):\n",
    "    \"Return result of executing `code` using python. If execution not permitted return `#FAIL#`\"\n",
    "    go = input(f'Proceed with execution?\\n```\\n{code}\\n```\\n')\n",
    "    if go.lower()!='y': return '#FAIL#'\n",
    "    return run(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c1b4face-7ec4-48ac-9d4d-12ad476f61cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = askgpt(\"What is 12 factorial?\",\n",
    "           system = \"Use python for any required computations.\",\n",
    "           functions=[schema(python)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a1290c5-3d22-4170-83a9-ad346f4e824d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "479001600"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_func(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c3826234-6012-4abf-950a-b9c7ec701c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    functions=[schema(python)],\n",
    "    messages = [{\"role\": \"user\", \"content\": \"What is 12 factorial?\"},\n",
    "                {\"role\": \"function\", \"name\": \"python\", \"content\": \"479001600\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0900aaf0-70ad-4712-a43b-986aa60f17ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 factorial, denoted as 12!, is the product of all positive integers from 1 to 12. \n",
      "\n",
      "Mathematically, 12! = 12 Ã— 11 Ã— 10 Ã— 9 Ã— 8 Ã— 7 Ã— 6 Ã— 5 Ã— 4 Ã— 3 Ã— 2 Ã— 1 = 479,001,600.\n"
     ]
    }
   ],
   "source": [
    "response(c.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "05ad805b-0cc2-4ad1-97b1-07929f33c63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = askgpt(\"What is the capital of France?\",\n",
    "           system = \"Use python for any required computations.\",\n",
    "           functions=[schema(python)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb401cae-8735-4f95-8631-4cd46bb921f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "response(c.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
