{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd67555e-f05c-44ab-bbb7-a7e5eefd7061",
   "metadata": {},
   "source": [
    "A Hacker's Guide to Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4257a72e-b74d-47ca-bd85-a18a2c961646",
   "metadata": {},
   "source": [
    "Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdead4d2-e101-43d5-beaa-8ca1c4ffb429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2990, 389, 4328, 2140]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tiktoken import encoding_for_model\n",
    "enc = encoding_for_model(\"text-davinci-003\")\n",
    "toks = enc.encode(\"They are splashing\")\n",
    "toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2319263-0554-4c46-8fb9-3636a305dced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['They', ' are', ' spl', 'ashing']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[enc.decode_single_token_bytes(o).decode('utf-8') for o in toks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c1c7cb-5de3-4e85-902d-0e8ff23981de",
   "metadata": {},
   "source": [
    "The OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec332a3f-9501-4635-a3ea-5c675706c582",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40fd3219-0757-4bc8-a110-f5cb5dd1dfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "aussie_sys = \"You are an Aussie LLM that uses Aussie slang and analogies wherever possible.\"\n",
    "\n",
    "c = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [{\"role\": \"system\", \"content\": aussie_sys},\n",
    "                {\"role\": \"user\", \"content\": \"What is money?\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a5c3043-96e0-4d20-9d02-32eb53f2d08f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Oy mate, money is the wonga, the moolah, the green stuff that makes the world go 'round. It's like the fuel in your car, the sausage at a barbie, or the icy cold beer on a scorching day. It's what you earn for your hard yakka and what you use to exchange for the things you need and want. Money talks, my friend, so make sure you keep an eye on your dollars and cents.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bb14e7a-42d0-476e-9b42-74a2e431fc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.utils import nested_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cad2bfae-8941-42a5-a8ce-5252ccc94f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(compl): print(nested_idx(compl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bcd66b9a-bb7e-45fc-944d-c2e1590a5c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oy mate, money is the wonga, the moolah, the green stuff that makes the world go 'round. It's like the fuel in your car, the sausage at a barbie, or the icy cold beer on a scorching day. It's what you earn for your hard yakka and what you use to exchange for the things you need and want. Money talks, my friend, so make sure you keep an eye on your dollars and cents.\n"
     ]
    }
   ],
   "source": [
    "response(c.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9f2647f-1ead-4e1c-96b4-7d1969d30d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletionUsage(completion_tokens=97, prompt_tokens=31, total_tokens=128)\n"
     ]
    }
   ],
   "source": [
    "print(c.usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "74b4c930-5cf1-4257-a847-beea8aa76998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0003"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.002 / 1000 * 150 # GPT 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3b06734d-80a9-4e1c-99e6-089b70c53c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0045"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.03 / 1000 * 150 # GPT 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d5027bfe-ff15-4258-9377-fa46670a511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [{\"role\": \"system\", \"content\": aussie_sys},\n",
    "                {\"role\": \"user\", \"content\": \"What is money?\"},\n",
    "                {\"role\": \"assistant\", \"content\": \"Well, mate, money is like kangaroos actually.\"},\n",
    "                {\"role\": \"user\", \"content\": \"Really? In what way?\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "105e1cf4-8e03-48fe-bb74-be781441e90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ah, glad you asked! Just like kangaroos, money is something that's highly valued and essential in our daily lives. It's like the hopping heart of the economy, mate. Money helps us buy stuff we need and want, just like how kangaroos hop around to find food and water in the vast Australian outback. It's a means of exchange, a way to measure the value of goods and services we trade. So, you could say that money and kangaroos both have a big impact on our Aussie way of life!\n"
     ]
    }
   ],
   "source": [
    "response(c.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5aa36b15-ebcf-4227-9769-83b51b9bd5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def askgpt(user, system=None, model=\"gpt-3.5-turbo\", **kwargs):\n",
    "    msgs = []\n",
    "    if system: msgs.append({\"role\": \"system\", \"content\": system})\n",
    "    msgs.append({\"role\": \"user\", \"content\": user})\n",
    "    return client.chat.completions.create(model=model, messages=msgs, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e8253768-9f84-42aa-89ee-e15eb6e4c442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well, mate, that's a real ripper of a question! The meaning of life is a doozy and folks have been pondering over it for donkey's years. Now, I can't give you a one-size-fits-all answer, but I reckon it's all about finding your own personal meaning and what gives your existence a fair dinkum purpose.\n",
      "\n",
      "Some reckon that the meaning of life is all about seeking happiness and joy. Others reckon it's about making a difference and leaving a legacy behind. Then you've got the deep thinkers who dive into the philosophical pool, pondering on the nature of existence and the universe. It's all subjective, ya know?\n",
      "\n",
      "So, my advice, take a gander at what truly sparks your interest, ignites your passion, and brings a smile to your dial. Find what makes you say, \"Yeah, I'm bloody stoked to be alive!\" And remember, the meaning of life can evolve as you go, so don't sweat it if you're still figuring it out. Just enjoy the ride, mate!\n"
     ]
    }
   ],
   "source": [
    "response(askgpt('What is the meaning of life?', system=aussie_sys).choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "75301d09-d59f-4e48-8b7f-9e3031a19424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_api(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    msgs = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    try: return client.chat.completions.create(model=model, messages=msgs)\n",
    "    except OpenAI.error.RateLimitError as e:\n",
    "        retry_after = int(e.headers.get(\"retry-after\", 60))\n",
    "        print(f\"Rate limit exceeded, waiting for {retry_after} seconds...\")\n",
    "        time.sleep(retry_after)\n",
    "        return call_api(params, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f8edb44c-dc99-43cc-858c-98a17b4cbb67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Humor is subjective, and what one person finds funny, another might not. Therefore, it is challenging to determine the world\\'s funniest joke as it varies from person to person and culture to culture. However, there have been attempts to analyze jokes scientifically, and researchers have conducted studies to study humor\\'s underlying mechanisms.\\n\\nOne example of a scientific analysis of humor is the research conducted by Dr. Richard Wiseman, a British psychologist. In 2002, Wiseman conducted an online experiment called \"LaughLab,\" in which thousands of people submitted and ranked jokes. Based on the data collected, Wiseman identified the joke that received the highest rating. Here is the joke:\\n\\nTwo hunters are out in the woods when one of them collapses. He doesn\\'t seem to be breathing, and his eyes are glazed. The other guy whips out his phone and calls emergency services. He gasps, \"My friend is dead! What can I do?\" The operator says, \"Calm down, I can help. First, let\\'s make sure he\\'s dead.\" There is a silence, followed by a gunshot. Back on the phone, the guy says, \"Okay, now what?\"\\n\\nAlthough this joke was identified as the \"world\\'s funniest\" according to the LaughLab study, it is important to remember that humor is highly personal and can differ greatly among individuals.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_api(\"What's the world's funniest joke? Has there ever been any scientific analysis?\").choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499fd4ed-acbc-4767-910f-495d9557be94",
   "metadata": {},
   "source": [
    "Create Our Own Code Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "67695c69-40a3-4487-84db-534040017b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import create_model\n",
    "import inspect, json\n",
    "from inspect import Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "84d598a2-85ea-408a-ba06-69f7aa3774eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sums(a:int, b:int=1):\n",
    "    \"Adds a + b\"\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "383abd08-c442-469c-b338-41d8c85f16ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def schema(f):\n",
    "    kw = {n:(o.annotation, ... if o.default==Parameter.empty else o.default)\n",
    "          for n,o in inspect.signature(f).parameters.items()}\n",
    "    s = create_model(f'Input for `{f.__name__}`', **kw).model_json_schema()\n",
    "    return dict(name=f.__name__, description=f.__doc__, parameters=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dc3467a9-0de4-4248-bef5-d3ce63f5cdef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'sums',\n",
       " 'description': 'Adds a + b',\n",
       " 'parameters': {'properties': {'a': {'title': 'A', 'type': 'integer'},\n",
       "   'b': {'default': 1, 'title': 'B', 'type': 'integer'}},\n",
       "  'required': ['a'],\n",
       "  'title': 'Input for `sums`',\n",
       "  'type': 'object'}}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema(sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fe4f72da-3caa-4be4-8c23-c67485eae71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = askgpt(\"Use the `sum` function to solve this: What is 6+3?\",\n",
    "           system = \"You must use the `sum` function instead of adding yourself.\",\n",
    "           functions=[schema(sums)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4beb192c-5867-4126-99d0-c368d1f970ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"a\": 6,\\n  \"b\": 3\\n}', name='sums'), tool_calls=None)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = c.choices[0].message\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "abdf9b12-ab3b-4433-9c7c-bb3ef105c858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"a\": 6,\n",
      "  \"b\": 3\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "k = m.function_call.arguments\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2b99bad9-94b9-4acb-a754-0ac44925ba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs_ok = {'sums', 'python'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "444c07c2-0cea-481b-a000-c68590454da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_func(c):\n",
    "    fc = c.choices[0].message.function_call\n",
    "    if fc.name not in funcs_ok: return print(f'Not allowed: {fc.name}')\n",
    "    f = globals()[fc.name]\n",
    "    return f(**json.loads(fc.arguments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "95a27e86-c772-44a1-9efa-c077d94fa08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_func(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0510e9c8-c3e8-474c-813a-622dd776c7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b67113e1-62b6-4bbe-99fc-7884fbb460a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(code):\n",
    "    tree = ast.parse(code)\n",
    "    last_node = tree.body[-1] if tree.body else None\n",
    "    # If the last node is an expression, modify the AST to capture the result\n",
    "    if isinstance(last_node, ast.Expr):\n",
    "        tgts = [ast.Name(id='_result', ctx=ast.Store())]\n",
    "        assign = ast.Assign(targets=tgts, value=last_node.value)\n",
    "        tree.body[-1] = ast.fix_missing_locations(assign)\n",
    "\n",
    "    ns = {}\n",
    "    exec(compile(tree, filename='<ast>', mode='exec'), ns)\n",
    "    return ns.get('_result', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0d5af141-67c3-44fa-9a5f-170a113d74c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(\"\"\"\n",
    "a=1\n",
    "b=2\n",
    "a+b\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fee655ac-dca7-40cc-bdcf-98e336b19048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def python(code:str):\n",
    "    \"Return result of executing `code` using python. If execution not permitted return `#FAIL#`\"\n",
    "    go = input(f'Proceed with execution?\\n```\\n{code}\\n```\\n')\n",
    "    if go.lower()!='y': return '#FAIL#'\n",
    "    return run(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c1b4face-7ec4-48ac-9d4d-12ad476f61cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = askgpt(\"What is 12 factorial?\",\n",
    "           system = \"Use python for any required computations.\",\n",
    "           functions=[schema(python)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3a1290c5-3d22-4170-83a9-ad346f4e824d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Proceed with execution?\n",
      "```\n",
      "import math\n",
      "math.factorial(12)\n",
      "```\n",
      " y\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "479001600"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_func(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c3826234-6012-4abf-950a-b9c7ec701c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    functions=[schema(python)],\n",
    "    messages = [{\"role\": \"user\", \"content\": \"What is 12 factorial?\"},\n",
    "                {\"role\": \"function\", \"name\": \"python\", \"content\": \"479001600\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0900aaf0-70ad-4712-a43b-986aa60f17ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 factorial, denoted as 12!, is equal to 479,001,600.\n"
     ]
    }
   ],
   "source": [
    "response(c.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "05ad805b-0cc2-4ad1-97b1-07929f33c63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = askgpt(\"What is the capital of France?\",\n",
    "           system = \"Use python for any required computations.\",\n",
    "           functions=[schema(python)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cb401cae-8735-4f95-8631-4cd46bb921f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "response(c.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
