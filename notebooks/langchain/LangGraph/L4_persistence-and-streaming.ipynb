{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5789bc3-b1ae-42c7-94a8-2ef4f89946fc",
   "metadata": {},
   "source": [
    "# Persistence and Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5762271-8736-4e94-9444-8c92bd0e8074",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0168aee-bce9-4d60-b827-f86a88187e31",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da06a64f-a2d5-4a66-8090-9ada0930c684",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "tool = TavilySearchResults(max_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2589c5b6-6cc2-4594-9a17-dccdcf676054",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c033522-d2fc-41ac-8e3c-5e35872bf88d",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2ba84ec-c172-4de7-ac55-e3158a531b23",
   "metadata": {
    "height": 574
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, model, tools, checkpointer, system=\"\"):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_openai)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\"llm\", self.exists_action, {True: \"action\", False: END})\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile(checkpointer=checkpointer)\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def call_openai(self, state: AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {'messages': [message]}\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            result = self.tools[t['name']].invoke(t['args'])\n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        print(\"Back to the model!\")\n",
    "        return {'messages': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "876d5092-b8ef-4e38-b4d7-0e80c609bf7a",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "abot = Agent(model, [tool], system=prompt, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10084a02-2928-4945-9f7c-ad3f5b33caf7",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in sf?\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "714d1205-f8fc-4912-b148-2a45da99219c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83588e70-254f-4f83-a510-c8ae81e729b0",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Ugee6dmSVsPPQ8rlnPE1T23C', 'function': {'arguments': '{\"query\":\"current weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 151, 'total_tokens': 173}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_4008e3b719', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-868d955d-eaef-4217-a8d6-5efc758a4e18-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_Ugee6dmSVsPPQ8rlnPE1T23C'}], usage_metadata={'input_tokens': 151, 'output_tokens': 22, 'total_tokens': 173})]\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_Ugee6dmSVsPPQ8rlnPE1T23C'}\n",
      "Back to the model!\n",
      "[ToolMessage(content='[{\\'url\\': \\'https://www.wunderground.com/hourly/us/ca/san-francisco/94120/date/2024-7-10\\', \\'content\\': \\'Current Weather for Popular Cities . San Francisco, CA 55 ° F Clear; Manhattan, NY 67 ° F Fair; Schiller Park, IL (60176) warning 58 ° F Clear; Boston, MA 73 ° F Cloudy; Houston, TX warning 84 ...\\'}, {\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.78, \\'lon\\': -122.42, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1719846355, \\'localtime\\': \\'2024-07-01 8:05\\'}, \\'current\\': {\\'last_updated_epoch\\': 1719846000, \\'last_updated\\': \\'2024-07-01 08:00\\', \\'temp_c\\': 15.6, \\'temp_f\\': 60.1, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Sunny\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/113.png\\', \\'code\\': 1000}, \\'wind_mph\\': 2.2, \\'wind_kph\\': 3.6, \\'wind_degree\\': 10, \\'wind_dir\\': \\'N\\', \\'pressure_mb\\': 1014.0, \\'pressure_in\\': 29.95, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 93, \\'cloud\\': 0, \\'feelslike_c\\': 15.6, \\'feelslike_f\\': 60.1, \\'windchill_c\\': 14.9, \\'windchill_f\\': 58.8, \\'heatindex_c\\': 14.8, \\'heatindex_f\\': 58.6, \\'dewpoint_c\\': 10.8, \\'dewpoint_f\\': 51.4, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 4.0, \\'gust_mph\\': 4.8, \\'gust_kph\\': 7.8}}\"}]', name='tavily_search_results_json', tool_call_id='call_Ugee6dmSVsPPQ8rlnPE1T23C')]\n",
      "[AIMessage(content='The current weather in San Francisco is:\\n\\n- **Temperature**: 60.1°F (15.6°C)\\n- **Condition**: Sunny\\n- **Wind**: 2.2 mph (3.6 kph) from the North\\n- **Humidity**: 93%\\n- **Visibility**: 9 miles (16 km)\\n- **Pressure**: 29.95 in (1014 mb)\\n- **UV Index**: 4\\n\\nEnjoy the sunny weather!', response_metadata={'token_usage': {'completion_tokens': 102, 'prompt_tokens': 684, 'total_tokens': 786}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_4008e3b719', 'finish_reason': 'stop', 'logprobs': None}, id='run-99ac580c-eea2-498a-a8b1-e926b65f430c-0', usage_metadata={'input_tokens': 684, 'output_tokens': 102, 'total_tokens': 786})]\n"
     ]
    }
   ],
   "source": [
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cb3ef4c-58b3-401b-b104-0d51e553d982",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_9DVwYWzIFGJqy36lzSh4WEKn', 'function': {'arguments': '{\"query\":\"current weather in Los Angeles\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 798, 'total_tokens': 820}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_4008e3b719', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-7e42c081-3b85-4721-8e3a-fefb5ec2809a-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Los Angeles'}, 'id': 'call_9DVwYWzIFGJqy36lzSh4WEKn'}], usage_metadata={'input_tokens': 798, 'output_tokens': 22, 'total_tokens': 820})]}\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Los Angeles'}, 'id': 'call_9DVwYWzIFGJqy36lzSh4WEKn'}\n",
      "Back to the model!\n",
      "{'messages': [ToolMessage(content='[{\\'url\\': \\'https://www.wunderground.com/hourly/us/ca/los-angeles/90053/date/2024-07-01\\', \\'content\\': \\'Weather Underground provides local & long-range weather forecasts, weatherreports, maps & tropical weather conditions for the Los Angeles area. ... Monday 07/01 Hourly for Tomorrow, Mon 07/01\\'}, {\\'url\\': \\'https://www.timeanddate.com/weather/usa/los-angeles/historic?month=1&year=2024\\', \\'content\\': \\'Weather reports from January 2024 in Los Angeles, California, USA with highs and lows. Sign in. News. News Home; Astronomy News; Time Zone News; ... See more current weather. ... 30.07 \"Hg: 10 mi: 4:53 pm: 64 °F: Sunny. 6 mph:\\'}]', name='tavily_search_results_json', tool_call_id='call_9DVwYWzIFGJqy36lzSh4WEKn')]}\n",
      "{'messages': [AIMessage(content=\"I couldn't find specific current weather details for Los Angeles in the initial search. Let me look again to provide you with accurate information.\", additional_kwargs={'tool_calls': [{'id': 'call_uw5xEnSna9cnG274tdMWc82e', 'function': {'arguments': '{\"query\":\"current weather in Los Angeles\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 1015, 'total_tokens': 1064}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_ce0793330f', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-c99fa8f4-1caa-420f-86b7-5054ae48280b-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Los Angeles'}, 'id': 'call_uw5xEnSna9cnG274tdMWc82e'}], usage_metadata={'input_tokens': 1015, 'output_tokens': 49, 'total_tokens': 1064})]}\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Los Angeles'}, 'id': 'call_uw5xEnSna9cnG274tdMWc82e'}\n",
      "Back to the model!\n",
      "{'messages': [ToolMessage(content='[{\\'url\\': \\'https://www.wunderground.com/hourly/us/ca/los-angeles/90053/date/2024-07-01\\', \\'content\\': \\'Weather Underground provides local & long-range weather forecasts, weatherreports, maps & tropical weather conditions for the Los Angeles area. ... Monday 07/01 Hourly for Tomorrow, Mon 07/01\\'}, {\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'Los Angeles\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 34.05, \\'lon\\': -118.24, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1719846392, \\'localtime\\': \\'2024-07-01 8:06\\'}, \\'current\\': {\\'last_updated_epoch\\': 1719846000, \\'last_updated\\': \\'2024-07-01 08:00\\', \\'temp_c\\': 17.2, \\'temp_f\\': 63.0, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Mist\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/143.png\\', \\'code\\': 1030}, \\'wind_mph\\': 4.3, \\'wind_kph\\': 6.8, \\'wind_degree\\': 90, \\'wind_dir\\': \\'E\\', \\'pressure_mb\\': 1013.0, \\'pressure_in\\': 29.91, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 87, \\'cloud\\': 0, \\'feelslike_c\\': 17.2, \\'feelslike_f\\': 63.0, \\'windchill_c\\': 23.3, \\'windchill_f\\': 74.0, \\'heatindex_c\\': 24.6, \\'heatindex_f\\': 76.3, \\'dewpoint_c\\': 12.8, \\'dewpoint_f\\': 55.1, \\'vis_km\\': 9.7, \\'vis_miles\\': 6.0, \\'uv\\': 6.0, \\'gust_mph\\': 8.7, \\'gust_kph\\': 14.0}}\"}]', name='tavily_search_results_json', tool_call_id='call_uw5xEnSna9cnG274tdMWc82e')]}\n",
      "{'messages': [AIMessage(content='The current weather in Los Angeles is:\\n\\n- **Temperature**: 63.0°F (17.2°C)\\n- **Condition**: Mist\\n- **Wind**: 4.3 mph (6.8 kph) from the East\\n- **Humidity**: 87%\\n- **Visibility**: 6 miles (9.7 km)\\n- **Pressure**: 29.91 in (1013 mb)\\n- **UV Index**: 6\\n\\nIt seems a bit misty out there!', response_metadata={'token_usage': {'completion_tokens': 108, 'prompt_tokens': 1559, 'total_tokens': 1667}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_ce0793330f', 'finish_reason': 'stop', 'logprobs': None}, id='run-adf6878a-85be-4185-bd2b-6ca5d1b0d016-0', usage_metadata={'input_tokens': 1559, 'output_tokens': 108, 'total_tokens': 1667})]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What about in la?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc3293b7-a50c-43c8-a022-8975e1e444b8",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='Currently, Los Angeles is warmer than San Francisco. \\n\\n- **San Francisco**: 60.1°F (15.6°C)\\n- **Los Angeles**: 63.0°F (17.2°C)\\n\\nSo, Los Angeles is approximately 2.9°F (1.6°C) warmer than San Francisco.', response_metadata={'token_usage': {'completion_tokens': 68, 'prompt_tokens': 1679, 'total_tokens': 1747}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_4008e3b719', 'finish_reason': 'stop', 'logprobs': None}, id='run-a2d2d4b4-36b4-4348-888a-f34549cfc7ca-0', usage_metadata={'input_tokens': 1679, 'output_tokens': 68, 'total_tokens': 1747})]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Which one is warmer?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0722c3d4-4cbf-43bf-81b0-50f634c4ce61",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='Could you please specify which locations or objects you are comparing to determine which one is warmer?', response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 149, 'total_tokens': 168}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_ce0793330f', 'finish_reason': 'stop', 'logprobs': None}, id='run-9ab565da-23d3-44b2-8a56-672b4a3f4c4a-0', usage_metadata={'input_tokens': 149, 'output_tokens': 19, 'total_tokens': 168})]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Which one is warmer?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace59a36-3941-459e-b9d1-ac5a4a1ed3ae",
   "metadata": {},
   "source": [
    "## Streaming tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b2f82fe-3ec4-4917-be51-9fb10d1317fa",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.aiosqlite import AsyncSqliteSaver\n",
    "\n",
    "memory = AsyncSqliteSaver.from_conn_string(\":memory:\")\n",
    "abot = Agent(model, [tool], system=prompt, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee0fe1c7-77e2-499c-a2f9-1f739bb6ddf0",
   "metadata": {
    "height": 200
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sayantanchakraborty\\workspaces\\poc-workspace\\gen-ai-playground\\.venv\\Lib\\site-packages\\langchain_core\\_api\\beta_decorator.py:87: LangChainBetaWarning: This API is in beta and may change in the future.\n",
      "  warn_beta(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_CLU4Gmg9M5H52Pb37gXhTx4n'}\n",
      "Back to the model!\n",
      "The| current| weather| in| San| Francisco| is| mostly| cloudy| with| a| temperature| of| |54|°F| and| wind| speeds| around| |8|.|1| mph|.|"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in SF?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "async for event in abot.graph.astream_events({\"messages\": messages}, thread, version=\"v1\"):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "        if content:\n",
    "            # Empty content in the context of OpenAI means\n",
    "            # that the model is asking for a tool to be invoked.\n",
    "            # So we only print non-empty content\n",
    "            print(content, end=\"|\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
